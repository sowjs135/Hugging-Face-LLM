{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47969f85-1c36-42e3-8628-e6f2e5d9bef1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64f5999a-ec4a-4835-8c09-42a6f986f14e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LLMs with Hugging Face\n",
    "\n",
    "In this notebook, we'll take a whirlwind tour of some top applications using Large Language Models (LLMs):\n",
    "* Summarization\n",
    "* Sentiment analysis\n",
    "* Translation\n",
    "* Zero-shot classification\n",
    "* Few-shot learning\n",
    "\n",
    "We will see how existing, open-source (and proprietary) models can be used out-of-the-box for many applications.  For this, we will use [Hugging Face models](https://huggingface.co/models) and some simple prompt engineering.\n",
    "\n",
    "We will then look at Hugging Face APIs in more detail to understand how to configure LLM pipelines.\n",
    "\n",
    "### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n",
    "1. Use a variety of existing models for a variety of common applications.\n",
    "1. Understand basic prompt engineering.\n",
    "1. Understand search vs. sampling for LLM inference.\n",
    "1. Get familiar with the main Hugging Face abstractions: datasets, pipelines, tokenizers, and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e4f446f-59a5-48b7-bb15-d16c3e8be2a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "681da96e-0f1f-4e24-b2a0-826bf8f17f3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Libraries:\n",
    "* [sacremoses](https://github.com/alvations/sacremoses) is for the translation model `Helsinki-NLP/opus-mt-en-es`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0ec4fec-7c94-43d0-bbd5-4e8a7def1355",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e61ed02-9df0-46ce-a938-f7fc3a6bb241",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: sacremoses==0.0.53 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7341b34c-51a4-4769-8161-99f338160f9e/lib/python3.10/site-packages (0.0.53)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from sacremoses==0.0.53) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from sacremoses==0.0.53) (1.2.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses==0.0.53) (1.16.0)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from sacremoses==0.0.53) (4.64.1)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.10/site-packages (from sacremoses==0.0.53) (2022.7.9)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install sacremoses==0.0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72bdd24e-b155-482a-b568-1b109cbeb6ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%run ../Includes/Classroom-Setup\n",
    "DA.paths.datasets = \"/dbfs/mnt/dbacademy-datasets/large-language-models/v01\"\n",
    "DA.paths.working_dir = \"/dbfs/mnt/dbacademy-users/sam.raymond@databricks.com/large-language-models\"\n",
    "DA.paths.user_db = \"dbfs:/mnt/dbacademy-users/sam.raymond@databricks.com/large-language-models/database.db\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee9b02b-40ff-4728-82b3-19b3a8e2fe3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Common LLM applications\n",
    "\n",
    "The goal of this section is to get your feet wet with several LLM applications and to show how easy it can be to get started with LLMs.\n",
    "\n",
    "As you go through the examples, note the datasets, models, APIs, and options used.  These simple examples can be starting points when you need to build your own application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee067453-a0bd-4592-b2af-60ba52472f24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2764c5a-c191-45e2-894b-ec03487b361a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Summarization\n",
    "\n",
    "Summarization can take two forms:\n",
    "* `extractive` (selecting representative excerpts from the text)\n",
    "* `abstractive` (generating novel text summaries)\n",
    "\n",
    "Here, we will use a model which does *abstractive* summarization.\n",
    "\n",
    "**Background reading**: The [Hugging Face summarization task page](https://huggingface.co/docs/transformers/tasks/summarization) lists model architectures which support summarization. The [summarization course chapter](https://huggingface.co/course/chapter7/5) provides a detailed walkthrough.\n",
    "\n",
    "In this section, we will use:\n",
    "* **Data**: [xsum](https://huggingface.co/datasets/xsum) dataset, which provides a set of BBC articles and summaries.\n",
    "* **Model**: [t5-small](https://huggingface.co/t5-small) model, which has 60 million parameters (242MB for PyTorch).  T5 is an encoder-decoder model created by Google which supports several tasks such as summarization, translation, Q&A, and text classification.  For more details, see the [Google blog post](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html), [code on GitHub](https://github.com/google-research/text-to-text-transfer-transformer), or the [research paper](https://arxiv.org/pdf/1910.10683.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c39f81e5-8d28-4c5c-a64d-21f22aa796e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b741b62ea91457e8859addf705b2fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d3f28ffb6d4a96b2da1b236010a7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:109: UserWarning: The dataset would be saved to both local disk and DBFS for better performance.\n  warnings.warn(\"The dataset would be saved to both local disk and DBFS for better performance.\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xsum/default to /local_disk0/v01/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5359a095b9bb45b09e7b0eda6f452f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fb8190ee9d4eb5b1065cf6a587d0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd2b61c023a43d39b93b291f2c4d76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ce074e6e7b462098f53131342b06c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf8e54c45124ac7b0030ea7c96ea3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9456f0ab528447a88a2939cc3f4dd4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xsum downloaded and prepared to /local_disk0/v01/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357da40d6ab84f649032882d7a1b52a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA.paths.datasets = \"/dbfs/mnt/dbacademy-datasets/large-language-models/v01\"\n",
    "xsum_dataset = load_dataset(\n",
    "    \"xsum\", version=\"1.2.0\", \n",
    "    cache_dir=DA.paths.datasets\n",
    "    \n",
    ")  # Note: We specify cache_dir to use predownloaded data.\n",
    "xsum_dataset  # The printed representation of this object shows the `num_rows` of each dataset split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed428893-b059-4bbd-a542-7a27e3ec5fe7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This dataset provides 3 columns:\n",
    "* `document`: the BBC article text\n",
    "* `summary`: a \"ground-truth\" summary --> Note how subjective this \"ground-truth\" is.  Is this the same summary you would write?  This a great example of how many LLM applications do not have obvious \"right\" answers.\n",
    "* `id`: article ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de4fe91-644a-4343-95e5-b7c693848bf3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>document</th><th>summary</th><th>id</th></tr></thead><tbody><tr><td>The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
       "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
       "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
       "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
       "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
       "The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\n",
       "Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\n",
       "However, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n",
       "\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n",
       "\"That may not be true but it is perhaps my perspective over the last few days.\n",
       "\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\n",
       "Meanwhile, a flood alert remains in place across the Borders because of the constant rain.\n",
       "Peebles was badly hit by problems, sparking calls to introduce more defences in the area.\n",
       "Scottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\n",
       "The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\n",
       "He said it was important to get the flood protection plan right but backed calls to speed up the process.\n",
       "\"I was quite taken aback by the amount of damage that has been done,\" he said.\n",
       "\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\n",
       "He said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\n",
       "Have you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.</td><td>Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.</td><td>35232142</td></tr><tr><td>A fire alarm went off at the Holiday Inn in Hope Street at about 04:20 BST on Saturday and guests were asked to leave the hotel.\n",
       "As they gathered outside they saw the two buses, parked side-by-side in the car park, engulfed by flames.\n",
       "One of the tour groups is from Germany, the other from China and Taiwan. It was their first night in Northern Ireland.\n",
       "The driver of one of the buses said many of the passengers had left personal belongings on board and these had been destroyed.\n",
       "Both groups have organised replacement coaches and will begin their tour of the north coast later than they had planned.\n",
       "Police have appealed for information about the attack.\n",
       "Insp David Gibson said: \"It appears as though the fire started under one of the buses before spreading to the second.\n",
       "\"While the exact cause is still under investigation, it is thought that the fire was started deliberately.\"</td><td>Two tourist buses have been destroyed by fire in a suspected arson attack in Belfast city centre.</td><td>40143035</td></tr><tr><td>Ferrari appeared in a position to challenge until the final laps, when the Mercedes stretched their legs to go half a second clear of the red cars.\n",
       "Sebastian Vettel will start third ahead of team-mate Kimi Raikkonen.\n",
       "The world champion subsequently escaped punishment for reversing in the pit lane, which could have seen him stripped of pole.\n",
       "But stewards only handed Hamilton a reprimand, after governing body the FIA said \"no clear instruction was given on where he should park\".\n",
       "Belgian Stoffel Vandoorne out-qualified McLaren team-mate Jenson Button on his Formula 1 debut.\n",
       "Vandoorne was 12th and Button 14th, complaining of a handling imbalance on his final lap but admitting the newcomer \"did a good job and I didn't\".\n",
       "Mercedes were wary of Ferrari's pace before qualifying after Vettel and Raikkonen finished one-two in final practice, and their concerns appeared to be well founded as the red cars mixed it with the silver through most of qualifying.\n",
       "After the first runs, Rosberg was ahead, with Vettel and Raikkonen splitting him from Hamilton, who made a mistake at the final corner on his first lap.\n",
       "But Hamilton saved his best for last, fastest in every sector of his final attempt, to beat Rosberg by just 0.077secs after the German had out-paced him throughout practice and in the first qualifying session.\n",
       "Vettel rued a mistake at the final corner on his last lap, but the truth is that with the gap at 0.517secs to Hamilton there was nothing he could have done.\n",
       "The gap suggests Mercedes are favourites for the race, even if Ferrari can be expected to push them.\n",
       "Vettel said: \"Last year we were very strong in the race and I think we are in good shape for tomorrow. We will try to give them a hard time.\"\n",
       "Vandoorne's preparations for his grand prix debut were far from ideal - he only found out he was racing on Thursday when FIA doctors declared Fernando Alonso unfit because of a broken rib sustained in his huge crash at the first race of the season in Australia two weeks ago.\n",
       "The Belgian rookie had to fly overnight from Japan, where he had been testing in the Super Formula car he races there, and arrived in Bahrain only hours before first practice on Friday.\n",
       "He also had a difficult final practice, missing all but the final quarter of the session because of a water leak.\n",
       "Button was quicker in the first qualifying session, but Vandoorne pipped him by 0.064secs when it mattered.\n",
       "The 24-year-old said: \"I knew after yesterday I had quite similar pace to Jenson and I knew if I improved a little bit I could maybe challenge him and even out-qualify him and that is what has happened.\n",
       "\"Jenson is a very good benchmark for me because he is a world champion and he is well known to the team so I am very satisfied with the qualifying.\"\n",
       "Button, who was 0.5secs quicker than Vandoorne in the first session, complained of oversteer on his final run in the second: \"Q1 was what I was expecting. Q2 he did a good job and I didn't. Very, very good job. We knew how quick he was.\"\n",
       "The controversial new elimination qualifying system was retained for this race despite teams voting at the first race in Australia to go back to the 2015 system.\n",
       "FIA president Jean Todt said earlier on Saturday that he \"felt it necessary to give new qualifying one more chance\", adding: \"We live in a world where there is too much over reaction.\"\n",
       "The system worked on the basis of mixing up the grid a little - Force India's Sergio Perez ended up out of position in 18th place after the team miscalculated the timing of his final run, leaving him not enough time to complete it before the elimination clock timed him out.\n",
       "But it will come in for more criticism as a result of lack of track action at the end of each session. There were three minutes at the end of the first session with no cars on the circuit, and the end of the second session was a similar damp squib.\n",
       "Only one car - Nico Hulkenberg's Force India - was out on the track with six minutes to go. The two Williams cars did go out in the final three minutes but were already through to Q3 and so nothing was at stake.\n",
       "The teams are meeting with Todt and F1 commercial boss Bernie Ecclestone on Sunday at noon local time to decide on what to do with qualifying for the rest of the season.\n",
       "Todt said he was \"optimistic\" they would be able to reach unanimous agreement on a change.\n",
       "\"We should listen to the people watching on TV,\" Rosberg said. \"If they are still unhappy, which I am sure they will be, we should change it.\"\n",
       "Red Bull's Daniel Ricciardo was fifth on the grid, ahead of the Williams cars of Valtteri Bottas and Felipe Massa and Force India's Nico Hulkenberg.\n",
       "Ricciardo's team-mate Daniil Kvyat was eliminated during the second session - way below the team's expectation - and the Renault of Brit Jolyon Palmer only managed 19th fastest.\n",
       "German Mercedes protege Pascal Wehrlein managed an excellent 16th in the Manor car.\n",
       "Bahrain GP qualifying results\n",
       "Bahrain GP coverage details</td><td>Lewis Hamilton stormed to pole position at the Bahrain Grand Prix ahead of Mercedes team-mate Nico Rosberg.</td><td>35951548</td></tr><tr><td>John Edward Bates, formerly of Spalding, Lincolnshire, but now living in London, faces a total of 22 charges, including two counts of indecency with a child.\n",
       "The 67-year-old is accused of committing the offences between March 1972 and October 1989.\n",
       "Mr Bates denies all the charges.\n",
       "Grace Hale, prosecuting, told the jury that the allegations of sexual abuse were made by made by four male complainants and related to when Mr Bates was a scout leader in South Lincolnshire and Cambridgeshire.\n",
       "\"The defendant says nothing of that sort happened between himself and all these individuals. He says they are all fabricating their accounts and telling lies,\" said Mrs Hale.\n",
       "The prosecutor claimed Mr Bates invited one 15 year old to his home offering him the chance to look at cine films made at scout camps but then showed him pornographic films.\n",
       "She told the jury that the boy was then sexually abused leaving him confused and frightened.\n",
       "Mrs Hale said: \"The complainant's recollection is that on a number of occasions sexual acts would happen with the defendant either in the defendant's car or in his cottage.\"\n",
       "She told the jury a second boy was taken by Mr Bates for a weekend in London at the age of 13 or 14 and after visiting pubs he was later sexually abused.\n",
       "Mrs Hale said two boys from the Spalding group had also made complaints of being sexually abused.\n",
       "The jury has been told that Mr Bates was in the RAF before serving as a Lincolnshire Police officer between 1976 and 1983.\n",
       "The trial, which is expected to last two weeks, continues.</td><td>A former Lincolnshire Police officer carried out a series of sex attacks on boys, a jury at Lincoln Crown Court was told.</td><td>36266422</td></tr><tr><td>Patients and staff were evacuated from Cerahpasa hospital on Wednesday after a man receiving treatment at the clinic threatened to shoot himself and others.\n",
       "Officers were deployed to negotiate with the man, a young police officer.\n",
       "Earlier reports that the armed man had taken several people hostage proved incorrect.\n",
       "The chief consultant of Cerahpasa hospital, Zekayi Kutlubay, who was evacuated from the facility, said that there had been \"no hostage crises\", adding that the man was \"alone in the room\".\n",
       "Dr Kutlubay said that the man had been receiving psychiatric treatment for the past two years.\n",
       "He said that the hospital had previously submitted a report stating that the man should not be permitted to carry a gun.\n",
       "\"His firearm was taken away,\" Dr Kutlubay said, adding that the gun in the officer's possession on Wednesday was not his issued firearm.\n",
       "The incident comes amid tension in Istanbul following several attacks in crowded areas, including the deadly assault on the Reina nightclub on New Year's Eve which left 39 people dead.</td><td>An armed man who locked himself into a room at a psychiatric hospital in Istanbul has ended his threat to kill himself, Turkish media report.</td><td>38826984</td></tr><tr><td>Simone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\n",
       "Rynard Landman and Ashton Hewitt got a try in either half for the Dragons.\n",
       "Glasgow showed far superior strength in depth as they took control of a messy match in the second period.\n",
       "Home coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\n",
       "Glasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\n",
       "It took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\n",
       "Glasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\n",
       "But the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\n",
       "The visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\n",
       "It was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\n",
       "Debutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\n",
       "The Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\n",
       "However, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\n",
       "Dragons director of rugby Lyn Jones said: \"We're disappointed to have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\n",
       "\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\n",
       "\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\n",
       "Glasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\n",
       "Replacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\n",
       "Dragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\n",
       "Replacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.</td><td>Defending Pro12 champions Glasgow Warriors bagged a late bonus-point victory over the Dragons despite a host of absentees and two yellow cards.</td><td>34540833</td></tr><tr><td>Veronica Vanessa Chango-Alverez, 31, was killed and another man injured when an Audi A3 struck them in Streatham High Road at 05:30 GMT on Saturday.\n",
       "Ten minutes before the crash the car was in London Road, Croydon, when a Volkswagen Passat collided with a tree.\n",
       "Police want to trace Nathan Davis, 27, who they say has links to the Audi. The car was abandoned at the scene.\n",
       "Ms Chango-Alverez died from multiple injuries, a post-mortem examination found.\n",
       "No arrests have been made as yet, police said.\n",
       "Ms Chango-Alverez was staying at her mother's home in Streatham High Road.\n",
       "She was born in Ecuador and had lived in London for 13 years, BBC London reporter Gareth Furby said. At the time of the crash, she was on her way to work in a hotel.\n",
       "The remains of the bus stop, which was extensively damaged in the crash, have been removed.\n",
       "Flowers have been left at the site in tribute to the victim.\n",
       "A statement from her brother Kevin Raul Chango-Alverez said: \"My family has had its heart torn out, at this Christmas time, we will never be the same again.\n",
       "\"On Friday night we were together as a family with Veronica meeting her newly born nephew and preparing for Christmas.\n",
       "\"I last saw her alive as she left to go to work on Saturday morning, but moments later I was holding her hand as she passed away in the street.\"\n",
       "Describing the crash as \"horrific\" Det Insp Gordon Wallace, said: \"The family are devastated. The memory of this senseless death will be with them each time they leave their home.\n",
       "\"The driver fled the scene abandoning the grey Audi, which was extensively damaged.\n",
       "\"We are looking to speak to Mr Nathan Davis in relation to this collision.\"\n",
       "The 51-year-old man injured at the bus stop remains in a critical condition in hospital while the condition of the 29-year-old driver of the Volkswagen is now stable.</td><td>A man with links to a car that was involved in a fatal bus stop crash in south London is being sought by police.</td><td>20836172</td></tr><tr><td>Belgian cyclist Demoitie died after a collision with a motorbike during Belgium's Gent-Wevelgem race.\n",
       "The 25-year-old was hit by the motorbike after several riders came down in a crash as the race passed through northern France.\n",
       "\"The main issues come when cars or motorbikes have to pass the peloton and pass riders,\" Team Sky's Rowe said.\n",
       "\"That is the fundamental issue we're looking into.\n",
       "\"There's a lot of motorbikes in and around the race whether it be cameras for TV, photographers or police motorbikes.\n",
       "\"In total there's around 50 motorbikes that work on each race.\n",
       "\"We've got a riders union and we're coming together to think of a few ideas, whether we cap a speed limit on how fast they can overtake us.\n",
       "\"Say we put a 10 kilometres per hour limit on it, if we're going 50kph they're only allowed to pass us 60kph or something like that.\"\n",
       "Demoitie, who was riding for the Wanty-Gobert team, was taken to hospital in Lille but died later.\n",
       "The sport's governing body, the UCI, said it would co-operate with all relevant authorities in an investigation into the incident.\n",
       "The Professional Cyclists' Association (CPA) issued a statement asking what would be done to improve safety.\n",
       "Despite Demoitie's death, attitudes to road racing will stay the same says Rowe, who has been competing in Three Days of De Panne race in Belgium.\n",
       "\"As soon as that element of fear slips into your mind and you start thinking of things that could happen, that's when you're doomed to fail,\" he told BBC Wales Sport.\n",
       "\"If you start thinking about crashes and the consequences and what could potentially happen then you're never going to be at the front of the peloton and you're never going to win any races.\"\n",
       "In a separate incident, another Belgian cyclist, Daan Myngheer, 22, died in hospital after suffering a heart attack during the first stage of the Criterium International in Corsica.</td><td>Welsh cyclist Luke Rowe says changes to the sport must be made following the death of Antoine Demoitie.</td><td>35932467</td></tr><tr><td>Gundogan, 26, told BBC Sport he \"can see the finishing line\" after tearing cruciate knee ligaments in December, but will not rush his return.\n",
       "The German missed the 2014 World Cup following back surgery that kept him out for a year, and sat out Euro 2016 because of a dislocated kneecap.\n",
       "He said: \"It is heavy mentally to accept that.\"\n",
       "Gundogan will not be fit for the start of the Premier League season at Brighton on 12 August but said his recovery time is now being measured in \"weeks\" rather than months.\n",
       "He told BBC Sport: \"It is really hard always to fall and fight your way back. You feel good and feel ready, then you get the next kick.\n",
       "\"The worst part is behind me now. I want to feel ready when I am fully back. I want to feel safe and confident. I don't mind if it is two weeks or six.\"\n",
       "Gundogan made 15 appearances and scored five goals in his debut season for City following his £20m move from Borussia Dortmund.\n",
       "He is eager to get on the field again and was impressed at the club's 4-1 win over Real Madrid in a pre-season game in Los Angeles on Wednesday.\n",
       "Manager Pep Guardiola has made five new signings already this summer and continues to have an interest in Arsenal forward Alexis Sanchez and Monaco's Kylian Mbappe.\n",
       "Gundogan said: \"Optimism for the season is big. It is huge, definitely.\n",
       "\"We felt that last year as well but it was a completely new experience for all of us. We know the Premier League a bit more now and can't wait for the season to start.\"\n",
       "City complete their three-match tour of the United States against Tottenham in Nashville on Saturday.\n",
       "Chelsea manager Antonio Conte said earlier this week he did not feel Tottenham were judged by the same standards as his own side, City and Manchester United.\n",
       "Spurs have had the advantage in their recent meetings with City, winning three and drawing one of their last four Premier League games.\n",
       "And Gundogan thinks they are a major threat.\n",
       "He said: \"Tottenham are a great team. They have the style of football. They have young English players. Our experience last season shows it is really tough to beat them.\n",
       "\"They are really uncomfortable to play against.\n",
       "\"I am pretty sure, even if they will not say it loud, the people who know the Premier League know Tottenham are definitely a competitor for the title.\"</td><td>Manchester City midfielder Ilkay Gundogan says it has been mentally tough to overcome a third major injury.</td><td>40758845</td></tr><tr><td>The crash happened about 07:20 GMT at the junction of the A127 and Progress Road in Leigh-on-Sea, Essex.\n",
       "The man, who police said is aged in his 20s, was treated at the scene for a head injury and suspected multiple fractures, the ambulance service said.\n",
       "He was airlifted to the Royal London Hospital for further treatment.\n",
       "The Southend-bound carriageway of the A127 was closed for about six hours while police conducted their initial inquiries.\n",
       "A spokeswoman for Essex Police said it was not possible comment to further as this time as the \"investigation is now being conducted by the IPCC\".</td><td>A jogger has been hit by an unmarked police car responding to an emergency call, leaving him with \"serious life-changing injuries\".</td><td>30358490</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n\"That may not be true but it is perhaps my perspective over the last few days.\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\nThe Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.",
         "Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.",
         "35232142"
        ],
        [
         "A fire alarm went off at the Holiday Inn in Hope Street at about 04:20 BST on Saturday and guests were asked to leave the hotel.\nAs they gathered outside they saw the two buses, parked side-by-side in the car park, engulfed by flames.\nOne of the tour groups is from Germany, the other from China and Taiwan. It was their first night in Northern Ireland.\nThe driver of one of the buses said many of the passengers had left personal belongings on board and these had been destroyed.\nBoth groups have organised replacement coaches and will begin their tour of the north coast later than they had planned.\nPolice have appealed for information about the attack.\nInsp David Gibson said: \"It appears as though the fire started under one of the buses before spreading to the second.\n\"While the exact cause is still under investigation, it is thought that the fire was started deliberately.\"",
         "Two tourist buses have been destroyed by fire in a suspected arson attack in Belfast city centre.",
         "40143035"
        ],
        [
         "Ferrari appeared in a position to challenge until the final laps, when the Mercedes stretched their legs to go half a second clear of the red cars.\nSebastian Vettel will start third ahead of team-mate Kimi Raikkonen.\nThe world champion subsequently escaped punishment for reversing in the pit lane, which could have seen him stripped of pole.\nBut stewards only handed Hamilton a reprimand, after governing body the FIA said \"no clear instruction was given on where he should park\".\nBelgian Stoffel Vandoorne out-qualified McLaren team-mate Jenson Button on his Formula 1 debut.\nVandoorne was 12th and Button 14th, complaining of a handling imbalance on his final lap but admitting the newcomer \"did a good job and I didn't\".\nMercedes were wary of Ferrari's pace before qualifying after Vettel and Raikkonen finished one-two in final practice, and their concerns appeared to be well founded as the red cars mixed it with the silver through most of qualifying.\nAfter the first runs, Rosberg was ahead, with Vettel and Raikkonen splitting him from Hamilton, who made a mistake at the final corner on his first lap.\nBut Hamilton saved his best for last, fastest in every sector of his final attempt, to beat Rosberg by just 0.077secs after the German had out-paced him throughout practice and in the first qualifying session.\nVettel rued a mistake at the final corner on his last lap, but the truth is that with the gap at 0.517secs to Hamilton there was nothing he could have done.\nThe gap suggests Mercedes are favourites for the race, even if Ferrari can be expected to push them.\nVettel said: \"Last year we were very strong in the race and I think we are in good shape for tomorrow. We will try to give them a hard time.\"\nVandoorne's preparations for his grand prix debut were far from ideal - he only found out he was racing on Thursday when FIA doctors declared Fernando Alonso unfit because of a broken rib sustained in his huge crash at the first race of the season in Australia two weeks ago.\nThe Belgian rookie had to fly overnight from Japan, where he had been testing in the Super Formula car he races there, and arrived in Bahrain only hours before first practice on Friday.\nHe also had a difficult final practice, missing all but the final quarter of the session because of a water leak.\nButton was quicker in the first qualifying session, but Vandoorne pipped him by 0.064secs when it mattered.\nThe 24-year-old said: \"I knew after yesterday I had quite similar pace to Jenson and I knew if I improved a little bit I could maybe challenge him and even out-qualify him and that is what has happened.\n\"Jenson is a very good benchmark for me because he is a world champion and he is well known to the team so I am very satisfied with the qualifying.\"\nButton, who was 0.5secs quicker than Vandoorne in the first session, complained of oversteer on his final run in the second: \"Q1 was what I was expecting. Q2 he did a good job and I didn't. Very, very good job. We knew how quick he was.\"\nThe controversial new elimination qualifying system was retained for this race despite teams voting at the first race in Australia to go back to the 2015 system.\nFIA president Jean Todt said earlier on Saturday that he \"felt it necessary to give new qualifying one more chance\", adding: \"We live in a world where there is too much over reaction.\"\nThe system worked on the basis of mixing up the grid a little - Force India's Sergio Perez ended up out of position in 18th place after the team miscalculated the timing of his final run, leaving him not enough time to complete it before the elimination clock timed him out.\nBut it will come in for more criticism as a result of lack of track action at the end of each session. There were three minutes at the end of the first session with no cars on the circuit, and the end of the second session was a similar damp squib.\nOnly one car - Nico Hulkenberg's Force India - was out on the track with six minutes to go. The two Williams cars did go out in the final three minutes but were already through to Q3 and so nothing was at stake.\nThe teams are meeting with Todt and F1 commercial boss Bernie Ecclestone on Sunday at noon local time to decide on what to do with qualifying for the rest of the season.\nTodt said he was \"optimistic\" they would be able to reach unanimous agreement on a change.\n\"We should listen to the people watching on TV,\" Rosberg said. \"If they are still unhappy, which I am sure they will be, we should change it.\"\nRed Bull's Daniel Ricciardo was fifth on the grid, ahead of the Williams cars of Valtteri Bottas and Felipe Massa and Force India's Nico Hulkenberg.\nRicciardo's team-mate Daniil Kvyat was eliminated during the second session - way below the team's expectation - and the Renault of Brit Jolyon Palmer only managed 19th fastest.\nGerman Mercedes protege Pascal Wehrlein managed an excellent 16th in the Manor car.\nBahrain GP qualifying results\nBahrain GP coverage details",
         "Lewis Hamilton stormed to pole position at the Bahrain Grand Prix ahead of Mercedes team-mate Nico Rosberg.",
         "35951548"
        ],
        [
         "John Edward Bates, formerly of Spalding, Lincolnshire, but now living in London, faces a total of 22 charges, including two counts of indecency with a child.\nThe 67-year-old is accused of committing the offences between March 1972 and October 1989.\nMr Bates denies all the charges.\nGrace Hale, prosecuting, told the jury that the allegations of sexual abuse were made by made by four male complainants and related to when Mr Bates was a scout leader in South Lincolnshire and Cambridgeshire.\n\"The defendant says nothing of that sort happened between himself and all these individuals. He says they are all fabricating their accounts and telling lies,\" said Mrs Hale.\nThe prosecutor claimed Mr Bates invited one 15 year old to his home offering him the chance to look at cine films made at scout camps but then showed him pornographic films.\nShe told the jury that the boy was then sexually abused leaving him confused and frightened.\nMrs Hale said: \"The complainant's recollection is that on a number of occasions sexual acts would happen with the defendant either in the defendant's car or in his cottage.\"\nShe told the jury a second boy was taken by Mr Bates for a weekend in London at the age of 13 or 14 and after visiting pubs he was later sexually abused.\nMrs Hale said two boys from the Spalding group had also made complaints of being sexually abused.\nThe jury has been told that Mr Bates was in the RAF before serving as a Lincolnshire Police officer between 1976 and 1983.\nThe trial, which is expected to last two weeks, continues.",
         "A former Lincolnshire Police officer carried out a series of sex attacks on boys, a jury at Lincoln Crown Court was told.",
         "36266422"
        ],
        [
         "Patients and staff were evacuated from Cerahpasa hospital on Wednesday after a man receiving treatment at the clinic threatened to shoot himself and others.\nOfficers were deployed to negotiate with the man, a young police officer.\nEarlier reports that the armed man had taken several people hostage proved incorrect.\nThe chief consultant of Cerahpasa hospital, Zekayi Kutlubay, who was evacuated from the facility, said that there had been \"no hostage crises\", adding that the man was \"alone in the room\".\nDr Kutlubay said that the man had been receiving psychiatric treatment for the past two years.\nHe said that the hospital had previously submitted a report stating that the man should not be permitted to carry a gun.\n\"His firearm was taken away,\" Dr Kutlubay said, adding that the gun in the officer's possession on Wednesday was not his issued firearm.\nThe incident comes amid tension in Istanbul following several attacks in crowded areas, including the deadly assault on the Reina nightclub on New Year's Eve which left 39 people dead.",
         "An armed man who locked himself into a room at a psychiatric hospital in Istanbul has ended his threat to kill himself, Turkish media report.",
         "38826984"
        ],
        [
         "Simone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\nRynard Landman and Ashton Hewitt got a try in either half for the Dragons.\nGlasgow showed far superior strength in depth as they took control of a messy match in the second period.\nHome coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\nGlasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\nIt took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\nGlasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\nBut the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\nThe visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\nIt was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\nDebutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\nThe Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\nHowever, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\nDragons director of rugby Lyn Jones said: \"We're disappointed to have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\n\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\n\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\nGlasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\nReplacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\nDragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\nReplacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.",
         "Defending Pro12 champions Glasgow Warriors bagged a late bonus-point victory over the Dragons despite a host of absentees and two yellow cards.",
         "34540833"
        ],
        [
         "Veronica Vanessa Chango-Alverez, 31, was killed and another man injured when an Audi A3 struck them in Streatham High Road at 05:30 GMT on Saturday.\nTen minutes before the crash the car was in London Road, Croydon, when a Volkswagen Passat collided with a tree.\nPolice want to trace Nathan Davis, 27, who they say has links to the Audi. The car was abandoned at the scene.\nMs Chango-Alverez died from multiple injuries, a post-mortem examination found.\nNo arrests have been made as yet, police said.\nMs Chango-Alverez was staying at her mother's home in Streatham High Road.\nShe was born in Ecuador and had lived in London for 13 years, BBC London reporter Gareth Furby said. At the time of the crash, she was on her way to work in a hotel.\nThe remains of the bus stop, which was extensively damaged in the crash, have been removed.\nFlowers have been left at the site in tribute to the victim.\nA statement from her brother Kevin Raul Chango-Alverez said: \"My family has had its heart torn out, at this Christmas time, we will never be the same again.\n\"On Friday night we were together as a family with Veronica meeting her newly born nephew and preparing for Christmas.\n\"I last saw her alive as she left to go to work on Saturday morning, but moments later I was holding her hand as she passed away in the street.\"\nDescribing the crash as \"horrific\" Det Insp Gordon Wallace, said: \"The family are devastated. The memory of this senseless death will be with them each time they leave their home.\n\"The driver fled the scene abandoning the grey Audi, which was extensively damaged.\n\"We are looking to speak to Mr Nathan Davis in relation to this collision.\"\nThe 51-year-old man injured at the bus stop remains in a critical condition in hospital while the condition of the 29-year-old driver of the Volkswagen is now stable.",
         "A man with links to a car that was involved in a fatal bus stop crash in south London is being sought by police.",
         "20836172"
        ],
        [
         "Belgian cyclist Demoitie died after a collision with a motorbike during Belgium's Gent-Wevelgem race.\nThe 25-year-old was hit by the motorbike after several riders came down in a crash as the race passed through northern France.\n\"The main issues come when cars or motorbikes have to pass the peloton and pass riders,\" Team Sky's Rowe said.\n\"That is the fundamental issue we're looking into.\n\"There's a lot of motorbikes in and around the race whether it be cameras for TV, photographers or police motorbikes.\n\"In total there's around 50 motorbikes that work on each race.\n\"We've got a riders union and we're coming together to think of a few ideas, whether we cap a speed limit on how fast they can overtake us.\n\"Say we put a 10 kilometres per hour limit on it, if we're going 50kph they're only allowed to pass us 60kph or something like that.\"\nDemoitie, who was riding for the Wanty-Gobert team, was taken to hospital in Lille but died later.\nThe sport's governing body, the UCI, said it would co-operate with all relevant authorities in an investigation into the incident.\nThe Professional Cyclists' Association (CPA) issued a statement asking what would be done to improve safety.\nDespite Demoitie's death, attitudes to road racing will stay the same says Rowe, who has been competing in Three Days of De Panne race in Belgium.\n\"As soon as that element of fear slips into your mind and you start thinking of things that could happen, that's when you're doomed to fail,\" he told BBC Wales Sport.\n\"If you start thinking about crashes and the consequences and what could potentially happen then you're never going to be at the front of the peloton and you're never going to win any races.\"\nIn a separate incident, another Belgian cyclist, Daan Myngheer, 22, died in hospital after suffering a heart attack during the first stage of the Criterium International in Corsica.",
         "Welsh cyclist Luke Rowe says changes to the sport must be made following the death of Antoine Demoitie.",
         "35932467"
        ],
        [
         "Gundogan, 26, told BBC Sport he \"can see the finishing line\" after tearing cruciate knee ligaments in December, but will not rush his return.\nThe German missed the 2014 World Cup following back surgery that kept him out for a year, and sat out Euro 2016 because of a dislocated kneecap.\nHe said: \"It is heavy mentally to accept that.\"\nGundogan will not be fit for the start of the Premier League season at Brighton on 12 August but said his recovery time is now being measured in \"weeks\" rather than months.\nHe told BBC Sport: \"It is really hard always to fall and fight your way back. You feel good and feel ready, then you get the next kick.\n\"The worst part is behind me now. I want to feel ready when I am fully back. I want to feel safe and confident. I don't mind if it is two weeks or six.\"\nGundogan made 15 appearances and scored five goals in his debut season for City following his £20m move from Borussia Dortmund.\nHe is eager to get on the field again and was impressed at the club's 4-1 win over Real Madrid in a pre-season game in Los Angeles on Wednesday.\nManager Pep Guardiola has made five new signings already this summer and continues to have an interest in Arsenal forward Alexis Sanchez and Monaco's Kylian Mbappe.\nGundogan said: \"Optimism for the season is big. It is huge, definitely.\n\"We felt that last year as well but it was a completely new experience for all of us. We know the Premier League a bit more now and can't wait for the season to start.\"\nCity complete their three-match tour of the United States against Tottenham in Nashville on Saturday.\nChelsea manager Antonio Conte said earlier this week he did not feel Tottenham were judged by the same standards as his own side, City and Manchester United.\nSpurs have had the advantage in their recent meetings with City, winning three and drawing one of their last four Premier League games.\nAnd Gundogan thinks they are a major threat.\nHe said: \"Tottenham are a great team. They have the style of football. They have young English players. Our experience last season shows it is really tough to beat them.\n\"They are really uncomfortable to play against.\n\"I am pretty sure, even if they will not say it loud, the people who know the Premier League know Tottenham are definitely a competitor for the title.\"",
         "Manchester City midfielder Ilkay Gundogan says it has been mentally tough to overcome a third major injury.",
         "40758845"
        ],
        [
         "The crash happened about 07:20 GMT at the junction of the A127 and Progress Road in Leigh-on-Sea, Essex.\nThe man, who police said is aged in his 20s, was treated at the scene for a head injury and suspected multiple fractures, the ambulance service said.\nHe was airlifted to the Royal London Hospital for further treatment.\nThe Southend-bound carriageway of the A127 was closed for about six hours while police conducted their initial inquiries.\nA spokeswoman for Essex Police said it was not possible comment to further as this time as the \"investigation is now being conducted by the IPCC\".",
         "A jogger has been hit by an unmarked police car responding to an emergency call, leaving him with \"serious life-changing injuries\".",
         "30358490"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "document",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "summary",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_sample = xsum_dataset[\"train\"].select(range(10))\n",
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d9cac23-1da5-4649-bc7f-ec2367d542b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We next use the Hugging Face `pipeline` tool to load a pre-trained model.  In this LLM pipeline constructor, we specify:\n",
    "* `task`: This first argument specifies the primary task.  See [Hugging Face tasks](https://huggingface.co/tasks) for more information.\n",
    "* `model`: This is the name of the pre-trained model from the [Hugging Face Hub](https://huggingface.co/models).\n",
    "* `min_length`, `max_length`: We want our generated summaries to be between these two token lengths.\n",
    "* `truncation`: Some input articles may be too long for the LLM to process.  Most LLMs have fixed limits on the length of input sequences.  This option tells the pipeline to truncate the input if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b893d7a-a525-433e-8e53-91a8f4a099be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622096>, line 7\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m summarizer \u001B[38;5;241m=\u001B[39m pipeline(\n",
       "\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummarization\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      4\u001B[0m     min_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m,\n",
       "\u001B[1;32m      5\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n",
       "\u001B[1;32m      6\u001B[0m     truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[0;32m----> 7\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n",
       "\u001B[1;32m      8\u001B[0m )  \u001B[38;5;66;03m# Note: We specify cache_dir to use predownloaded models.\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622096>, line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m summarizer \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummarization\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     min_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m,\n\u001B[1;32m      5\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n\u001B[1;32m      6\u001B[0m     truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m----> 7\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n\u001B[1;32m      8\u001B[0m )  \u001B[38;5;66;03m# Note: We specify cache_dir to use predownloaded models.\u001B[39;00m\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=40,\n",
    "    truncation=True,\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")  # Note: We specify cache_dir to use predownloaded models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da7acc2c-9a7a-4ae1-8c17-9f783fc8a896",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622097>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Apply to 1 article\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622097>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Apply to 1 article\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'summarizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply to 1 article\n",
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d151ef3d-f518-4c61-bdad-f6a10f2740cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622098>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Apply to a batch of articles\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622098>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Apply to a batch of articles\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'summarizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply to a batch of articles\n",
    "results = summarizer(xsum_sample[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce52f340-3085-4acf-8725-9afa28125aed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622099>, line 6\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Display the generated summary side-by-side with the reference summary and original document.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# We use Pandas to join the inputs and outputs together in a nice format.\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m display(\n",
       "\u001B[0;32m----> 6\u001B[0m     pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(results)\n",
       "\u001B[1;32m      7\u001B[0m     \u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_text\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
       "\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mjoin(pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(xsum_sample))[\n",
       "\u001B[1;32m      9\u001B[0m         [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
       "\u001B[1;32m     10\u001B[0m     ]\n",
       "\u001B[1;32m     11\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'results' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622099>, line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Display the generated summary side-by-side with the reference summary and original document.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# We use Pandas to join the inputs and outputs together in a nice format.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      5\u001B[0m display(\n\u001B[0;32m----> 6\u001B[0m     pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(results)\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_text\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mjoin(pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(xsum_sample))[\n\u001B[1;32m      9\u001B[0m         [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     10\u001B[0m     ]\n\u001B[1;32m     11\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'results' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'results' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the generated summary side-by-side with the reference summary and original document.\n",
    "# We use Pandas to join the inputs and outputs together in a nice format.\n",
    "import pandas as pd\n",
    "\n",
    "display(\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"summary_text\": \"generated_summary\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(xsum_sample))[\n",
    "        [\"generated_summary\", \"summary\", \"document\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b087b7d-a64c-4704-bb79-ca646fddd415",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "Sentiment analysis is a text classification task of estimating whether a piece of text is positive, negative, or another \"sentiment\" label.  The precise set of sentiment labels can vary across applications.\n",
    "\n",
    "**Background reading**: See the Hugging Face [task page on text classification](https://huggingface.co/tasks/text-classification) or [Wikipedia on sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis).\n",
    "\n",
    "In this section, we will use:\n",
    "* **Data**: [poem sentiment](https://huggingface.co/datasets/poem_sentiment) dataset, which provides lines from poems tagged with sentiments `negative` (0), `positive` (1), `no_impact` (2), or `mixed` (3).\n",
    "* **Model**: [fine-tuned version of BERT](https://huggingface.co/nickwong64/bert-base-uncased-poems-sentiment).  BERT, or Bidirectional Encoder Representations from Transformers, is an encoder-only model from Google usable for 11+ tasks such as sentiment analysis and entity recognition.  For more details, see this [Hugging Face blog post](https://huggingface.co/blog/bert-101) or the [Wikipedia page](https://en.wikipedia.org/wiki/BERT_&#40;language_model&#41;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2fba5e8-9e1e-492c-ab69-218cade86db8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622101>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m poem_dataset \u001B[38;5;241m=\u001B[39m load_dataset(\n",
       "\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpoem_sentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m, version\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets\n",
       "\u001B[1;32m      3\u001B[0m )\n",
       "\u001B[1;32m      4\u001B[0m poem_sample \u001B[38;5;241m=\u001B[39m poem_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m))\n",
       "\u001B[1;32m      5\u001B[0m display(poem_sample\u001B[38;5;241m.\u001B[39mto_pandas())\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622101>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m poem_dataset \u001B[38;5;241m=\u001B[39m load_dataset(\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpoem_sentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m, version\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets\n\u001B[1;32m      3\u001B[0m )\n\u001B[1;32m      4\u001B[0m poem_sample \u001B[38;5;241m=\u001B[39m poem_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m      5\u001B[0m display(poem_sample\u001B[38;5;241m.\u001B[39mto_pandas())\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poem_dataset = load_dataset(\n",
    "    \"poem_sentiment\", version=\"1.0.0\", cache_dir=DA.paths.datasets\n",
    ")\n",
    "poem_sample = poem_dataset[\"train\"].select(range(10))\n",
    "display(poem_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ff5425-e403-4234-ad25-ec021fbc90ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We load the pipeline using the task `text-classification` since we want to classify text with a fixed set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5456d690-f248-4e13-b8c0-7a3a03cc416e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622103>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m sentiment_classifier \u001B[38;5;241m=\u001B[39m pipeline(\n",
       "\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnickwong64/bert-base-uncased-poems-sentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[0;32m----> 4\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n",
       "\u001B[1;32m      5\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622103>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m sentiment_classifier \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnickwong64/bert-base-uncased-poems-sentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 4\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n\u001B[1;32m      5\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"nickwong64/bert-base-uncased-poems-sentiment\",\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e61b990-00d9-4273-bec5-45d9b27f993b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622104>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43msentiment_classifier\u001B[49m(poem_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverse_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'sentiment_classifier' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622104>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43msentiment_classifier\u001B[49m(poem_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverse_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'sentiment_classifier' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'sentiment_classifier' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = sentiment_classifier(poem_sample[\"verse_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e112f2e0-0b42-4ad9-9d8c-679e376be33d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622105>, line 6\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Display the predicted sentiment side-by-side with the ground-truth label and original text.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# The score indicates the model's confidence in its prediction.\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Join predictions with ground-truth data\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m joined_data \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[0;32m----> 6\u001B[0m     pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(results)\n",
       "\u001B[1;32m      7\u001B[0m     \u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted_label\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
       "\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mjoin(pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(poem_sample)\u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue_label\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
       "\u001B[1;32m      9\u001B[0m )\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Change label indices to text labels\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m sentiment_labels \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositive\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m2\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_impact\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m3\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'results' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622105>, line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Display the predicted sentiment side-by-side with the ground-truth label and original text.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# The score indicates the model's confidence in its prediction.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Join predictions with ground-truth data\u001B[39;00m\n\u001B[1;32m      5\u001B[0m joined_data \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m----> 6\u001B[0m     pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(results)\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted_label\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mjoin(pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(poem_sample)\u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue_label\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      9\u001B[0m )\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Change label indices to text labels\u001B[39;00m\n\u001B[1;32m     12\u001B[0m sentiment_labels \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositive\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m2\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_impact\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m3\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\n\u001B[0;31mNameError\u001B[0m: name 'results' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'results' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the predicted sentiment side-by-side with the ground-truth label and original text.\n",
    "# The score indicates the model's confidence in its prediction.\n",
    "\n",
    "# Join predictions with ground-truth data\n",
    "joined_data = (\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"label\": \"predicted_label\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(poem_sample).rename({\"label\": \"true_label\"}, axis=1))\n",
    ")\n",
    "\n",
    "# Change label indices to text labels\n",
    "sentiment_labels = {0: \"negative\", 1: \"positive\", 2: \"no_impact\", 3: \"mixed\"}\n",
    "joined_data = joined_data.replace({\"true_label\": sentiment_labels})\n",
    "\n",
    "display(joined_data[[\"predicted_label\", \"true_label\", \"score\", \"verse_text\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16f8cba-69c5-4334-91f4-d1642d6b8ded",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Translation\n",
    "\n",
    "Translation models may be designed for specific pairs of languages, or they may support more than two languages.  We will see both below.\n",
    "\n",
    "**Background reading**: See the Hugging Face [task page on translation](https://huggingface.co/tasks/translation) or the [Wikipedia page on machine translation](https://en.wikipedia.org/wiki/Machine_translation).\n",
    "\n",
    "In this section, we will use:\n",
    "* **Data**: We will use some example hard-coded sentences.  However, there are a variety of [translation datasets](https://huggingface.co/datasets?task_categories=task_categories:translation&sort=downloads) available from Hugging Face.\n",
    "* **Models**:\n",
    "   * [Helsinki-NLP/opus-mt-en-es](https://huggingface.co/Helsinki-NLP/opus-mt-en-es) is used for the first example of English (\"en\") to Spanish (\"es\") translation.  This model is based on [Marian NMT](https://marian-nmt.github.io/), a neural machine translation framework developed by Microsoft and other researchers.  See the [GitHub page](https://github.com/Helsinki-NLP/Opus-MT) for code and links to related resources.\n",
    "   * [t5-small](https://huggingface.co/t5-small) model, which has 60 million parameters (242MB for PyTorch).  T5 is an encoder-decoder model created by Google which supports several tasks such as summarization, translation, Q&A, and text classification.  For more details, see the [Google blog post](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html), [code on GitHub](https://github.com/google-research/text-to-text-transfer-transformer), or the [research paper](https://arxiv.org/pdf/1910.10683.pdf).  For our purposes, it supports translation for English, French, Romanian, and German."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a69cc66-5d2c-4661-ad49-581093cf3250",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Some models are designed for specific language-to-language translation.  Below, we use an English-to-Spanish model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87390f3e-0795-41e8-89e1-bf0a6db001b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622108>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m en_to_es_translation_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n",
       "\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHelsinki-NLP/opus-mt-en-es\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[0;32m----> 4\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n",
       "\u001B[1;32m      5\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622108>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m en_to_es_translation_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHelsinki-NLP/opus-mt-en-es\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 4\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n\u001B[1;32m      5\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_to_es_translation_pipeline = pipeline(\n",
    "    task=\"translation\",\n",
    "    model=\"Helsinki-NLP/opus-mt-en-es\",\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a7073d4-29c8-4bd7-af60-c6dc915482e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622109>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43men_to_es_translation_pipeline\u001B[49m(\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExisting, open-source (and proprietary) models can be used out-of-the-box for many applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      3\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'en_to_es_translation_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622109>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43men_to_es_translation_pipeline\u001B[49m(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExisting, open-source (and proprietary) models can be used out-of-the-box for many applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'en_to_es_translation_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'en_to_es_translation_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_to_es_translation_pipeline(\n",
    "    \"Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d67de4ff-9da4-48ca-9a9f-767a7e5e974b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Other models are designed to handle multiple languages.  Below, we show this with `t5-small`.  Note that, since it supports multiple languages (and tasks), we give it an explicit instruction to translate from one language to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ec3582-efc3-4fa1-85ea-19f340a92a8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622111>, line 5\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m t5_small_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n",
       "\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext2text-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      4\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n",
       "\u001B[0;32m----> 5\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n",
       "\u001B[1;32m      6\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622111>, line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m t5_small_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext2text-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n\u001B[0;32m----> 5\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n\u001B[1;32m      6\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5_small_pipeline = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=\"t5-small\",\n",
    "    max_length=50,\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c7367fd-bdce-4317-918d-afee98828969",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622112>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mt5_small_pipeline\u001B[49m(\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslate English to French: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      3\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 't5_small_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622112>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mt5_small_pipeline\u001B[49m(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslate English to French: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 't5_small_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 't5_small_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5_small_pipeline(\n",
    "    \"translate English to French: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf6114d1-5f32-4fb6-8a9d-3d73b099182c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622113>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mt5_small_pipeline\u001B[49m(\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslate English to Romanian: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      3\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 't5_small_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622113>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mt5_small_pipeline\u001B[49m(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranslate English to Romanian: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 't5_small_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 't5_small_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5_small_pipeline(\n",
    "    \"translate English to Romanian: Existing, open-source (and proprietary) models can be used out-of-the-box for many applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "554e5a0d-f6a4-494e-acf9-2800feaa93ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Zero-shot classification\n",
    "\n",
    "Zero-shot classification (or zero-shot learning) is the task of classifying a piece of text into one of a few given categories or labels, without having explicitly trained the model to predict those categories beforehand.  The idea appeared in literature before modern LLMs, but recent advances in LLMs have made zero-shot learning much more flexible and powerful.\n",
    "\n",
    "**Background reading**: See the Hugging Face [task page on zero-shot classification](https://huggingface.co/tasks/zero-shot-classification) or [Wikipedia on zero-shot learning](https://en.wikipedia.org/wiki/Zero-shot_learning).\n",
    "\n",
    "In this section, we will use:\n",
    "* **Data**: a few example articles from the [xsum](https://huggingface.co/datasets/xsum) dataset used in the Summarization section above.  Our goal is to label news articles under a few categories.\n",
    "* **Model**: [nli-deberta-v3-small](https://huggingface.co/cross-encoder/nli-deberta-v3-small), a fine-tuned version of the DeBERTa model.  The DeBERTa base model was developed by Microsoft and is one of several models derived from BERT; for more details on DeBERTa, see the [Hugging Face doc page](https://huggingface.co/docs/transformers/model_doc/deberta), the [code on GitHub](https://github.com/microsoft/DeBERTa), or the [research paper](https://arxiv.org/abs/2006.03654)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9782c962-0c1c-4fa4-a033-72c681c25fc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622115>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m zero_shot_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n",
       "\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzero-shot-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcross-encoder/nli-deberta-v3-small\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[0;32m----> 4\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: DA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n",
       "\u001B[1;32m      5\u001B[0m )\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcategorize_article\u001B[39m(article: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    This helper function defines the categories (labels) which the model must use to label articles.\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m    Note that our model was NOT fine-tuned to use these specific labels,\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m    This function then prints out the predicted labels alongside their confidence scores.\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622115>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m zero_shot_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m      2\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzero-shot-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcross-encoder/nli-deberta-v3-small\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 4\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: DA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcategorize_article\u001B[39m(article: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    This helper function defines the categories (labels) which the model must use to label articles.\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m    Note that our model was NOT fine-tuned to use these specific labels,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m    This function then prints out the predicted labels alongside their confidence scores.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_shot_pipeline = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-deberta-v3-small\",\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")\n",
    "\n",
    "\n",
    "def categorize_article(article: str) -> None:\n",
    "    \"\"\"\n",
    "    This helper function defines the categories (labels) which the model must use to label articles.\n",
    "    Note that our model was NOT fine-tuned to use these specific labels,\n",
    "    but it \"knows\" what the labels mean from its more general training.\n",
    "\n",
    "    This function then prints out the predicted labels alongside their confidence scores.\n",
    "    \"\"\"\n",
    "    results = zero_shot_pipeline(\n",
    "        article,\n",
    "        candidate_labels=[\n",
    "            \"politics\",\n",
    "            \"finance\",\n",
    "            \"sports\",\n",
    "            \"science and technology\",\n",
    "            \"pop culture\",\n",
    "            \"breaking news\",\n",
    "        ],\n",
    "    )\n",
    "    # Print the results nicely\n",
    "    del results[\"sequence\"]\n",
    "    display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "606ad232-ccfd-479c-937b-4f7493c54d92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622116>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mcategorize_article\u001B[49m(\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mSimone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mRynard Landman and Ashton Hewitt got a try in either half for the Dragons.\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mGlasgow showed far superior strength in depth as they took control of a messy match in the second period.\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03mHome coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03mGlasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mIt took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03mGlasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03mBut the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03mThe visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03mIt was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03mDebutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03mThe Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03mHowever, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\u001B[39;00m\n",
       "\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03mDragons director of rugby Lyn Jones said: \"We're disappointed to have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\u001B[39;00m\n",
       "\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03m\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\u001B[39;00m\n",
       "\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\u001B[39;00m\n",
       "\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03mGlasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\u001B[39;00m\n",
       "\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03mReplacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\u001B[39;00m\n",
       "\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mDragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\u001B[39;00m\n",
       "\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03mReplacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.\u001B[39;00m\n",
       "\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m     24\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'categorize_article' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622116>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcategorize_article\u001B[49m(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mSimone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mRynard Landman and Ashton Hewitt got a try in either half for the Dragons.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mGlasgow showed far superior strength in depth as they took control of a messy match in the second period.\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03mHome coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03mGlasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mIt took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03mGlasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03mBut the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03mThe visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03mIt was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03mDebutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03mThe Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03mHowever, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03mDragons director of rugby Lyn Jones said: \"We're disappointed to have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03m\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03mGlasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03mReplacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mDragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03mReplacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'categorize_article' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'categorize_article' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorize_article(\n",
    "    \"\"\"\n",
    "Simone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\n",
    "Rynard Landman and Ashton Hewitt got a try in either half for the Dragons.\n",
    "Glasgow showed far superior strength in depth as they took control of a messy match in the second period.\n",
    "Home coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\n",
    "Glasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\n",
    "It took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\n",
    "Glasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\n",
    "But the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\n",
    "The visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\n",
    "It was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\n",
    "Debutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\n",
    "The Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\n",
    "However, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\n",
    "Dragons director of rugby Lyn Jones said: \"We're disappointed to have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\n",
    "\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\n",
    "\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\n",
    "Glasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\n",
    "Replacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\n",
    "Dragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\n",
    "Replacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e6a8bd-ea74-47d4-85f5-54afddb181e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622117>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mcategorize_article\u001B[49m(\n",
       "\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThe full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03mMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03mFirst Minister Nicola Sturgeon visited the area to inspect the damage.\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03mJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03mHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m\"That may not be true but it is perhaps my perspective over the last few days.\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03mMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03mPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\u001B[39;00m\n",
       "\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03mScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\u001B[39;00m\n",
       "\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mThe Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\u001B[39;00m\n",
       "\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03mHe said it was important to get the flood protection plan right but backed calls to speed up the process.\u001B[39;00m\n",
       "\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"I was quite taken aback by the amount of damage that has been done,\" he said.\u001B[39;00m\n",
       "\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03m\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\u001B[39;00m\n",
       "\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\u001B[39;00m\n",
       "\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03mHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\u001B[39;00m\n",
       "\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m     24\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'categorize_article' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622117>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcategorize_article\u001B[49m(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThe full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03mMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03mFirst Minister Nicola Sturgeon visited the area to inspect the damage.\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03mJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03mHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m\"That may not be true but it is perhaps my perspective over the last few days.\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03mMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03mPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03mScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mThe Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03mHe said it was important to get the flood protection plan right but backed calls to speed up the process.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"I was quite taken aback by the amount of damage that has been done,\" he said.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03m\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03mHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'categorize_article' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'categorize_article' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorize_article(\n",
    "    \"\"\"\n",
    "The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
    "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
    "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
    "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
    "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
    "The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\n",
    "Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\n",
    "However, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n",
    "\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n",
    "\"That may not be true but it is perhaps my perspective over the last few days.\n",
    "\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\n",
    "Meanwhile, a flood alert remains in place across the Borders because of the constant rain.\n",
    "Peebles was badly hit by problems, sparking calls to introduce more defences in the area.\n",
    "Scottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\n",
    "The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\n",
    "He said it was important to get the flood protection plan right but backed calls to speed up the process.\n",
    "\"I was quite taken aback by the amount of damage that has been done,\" he said.\n",
    "\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\n",
    "He said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\n",
    "Have you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ee0e2b2-86a3-4c33-89b2-100c613447bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Few-shot learning\n",
    "\n",
    "In few-shot learning tasks, you give the model an instruction, a few query-response examples of how to follow that instruction, and then a new query.  The model must generate the response for that new query.  This technique has pros and cons: it is very powerful and allows models to be reused for many more applications, but it can be finicky and require significant prompt engineering to get good and reliable results.\n",
    "\n",
    "**Background reading**: See the [Wikipedia page on few-shot learning](https://en.wikipedia.org/wiki/Few-shot_learning_&#40;natural_language_processing&#41;) or [this Hugging Face blog about few-shot learning](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api).\n",
    "\n",
    "In this section, we will use:\n",
    "* **Task**: Few-shot learning can be applied to many tasks.  Here, we will do sentiment analysis, which was covered earlier.  However, you will see how few-shot learning allows us to specify custom labels, whereas the previous model was tuned for a specific set of labels.  We will also show other (toy) tasks at the end.  In terms of the Hugging Face `task` specified in the `pipeline` constructor, few-shot learning is handled as a `text-generation` task.\n",
    "* **Data**: We use a few examples, including a tweet example from the blog post linked above.\n",
    "* **Model**: [gpt-neo-1.3B](https://huggingface.co/EleutherAI/gpt-neo-1.3B), a version of the GPT-Neo model discussed in the blog linked above.  It is a transformer model with 1.3 billion parameters developed by Eleuther AI.  For more details, see the [code on GitHub](https://github.com/EleutherAI/gpt-neo) or the [research paper](https://arxiv.org/abs/2204.06745)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3486273c-486d-4a29-b509-382e5d527ea1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622119>, line 6\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We will limit the response length for our few-shot learning tasks.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m few_shot_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n",
       "\u001B[1;32m      3\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/gpt-neo-1.3B\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      5\u001B[0m     max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n",
       "\u001B[0;32m----> 6\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n",
       "\u001B[1;32m      7\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622119>, line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We will limit the response length for our few-shot learning tasks.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m few_shot_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m      3\u001B[0m     task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEleutherAI/gpt-neo-1.3B\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m----> 6\u001B[0m     model_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDA\u001B[49m\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets},\n\u001B[1;32m      7\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will limit the response length for our few-shot learning tasks.\n",
    "few_shot_pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"EleutherAI/gpt-neo-1.3B\",\n",
    "    max_new_tokens=10,\n",
    "    model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c9e6adb-88d9-40fe-9892-b602e335c9d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "***Tip***: In the few-shot prompts below, we separate the examples with a special token \"###\" and use the same token to encourage the LLM to end its output after answering the query.  We will tell the pipeline to use that special token as the end-of-sequence (EOS) token below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e69816f8-ee8a-4598-8079-2a1d233235fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622121>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Get the token ID for \"###\", which we will use as the EOS token below.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m eos_token_id \u001B[38;5;241m=\u001B[39m \u001B[43mfew_shot_pipeline\u001B[49m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m###\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622121>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Get the token ID for \"###\", which we will use as the EOS token below.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m eos_token_id \u001B[38;5;241m=\u001B[39m \u001B[43mfew_shot_pipeline\u001B[49m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m###\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the token ID for \"###\", which we will use as the EOS token below.\n",
    "eos_token_id = few_shot_pipeline.tokenizer.encode(\"###\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dc72ba6-dfe3-4da9-a6d6-4d80c03d2abe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622122>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Without any examples, the model output is inconsistent and usually incorrect.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each tweet, describe its sentiment:\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This new music video was incredible\"\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[Sentiment]:\"\"\"\u001B[39;00m,\n",
       "\u001B[1;32m      7\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n",
       "\u001B[1;32m      8\u001B[0m )\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622122>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Without any examples, the model output is inconsistent and usually incorrect.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each tweet, describe its sentiment:\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This new music video was incredible\"\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[Sentiment]:\"\"\"\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Without any examples, the model output is inconsistent and usually incorrect.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0536aa33-dc3a-404e-8c7d-b2455669c705",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622123>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# With only 1 example, the model may or may not get the answer right.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each tweet, describe its sentiment:\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This is the link to the article\"\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[Sentiment]: Neutral\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This new music video was incredible\"\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[Sentiment]:\"\"\"\u001B[39;00m,\n",
       "\u001B[1;32m     10\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n",
       "\u001B[1;32m     11\u001B[0m )\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622123>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# With only 1 example, the model may or may not get the answer right.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each tweet, describe its sentiment:\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This is the link to the article\"\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[Sentiment]: Neutral\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This new music video was incredible\"\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[Sentiment]:\"\"\"\u001B[39;00m,\n\u001B[1;32m     10\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With only 1 example, the model may or may not get the answer right.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1502760-a2ee-4a74-854f-a62d60188cec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622124>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# With 1 example for each sentiment, the model is more likely to understand!\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each tweet, describe its sentiment:\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[Tweet]: \"I hate it when my phone battery dies.\"\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[Sentiment]: Negative\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[Tweet]: \"My day has been 👍\"\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[Sentiment]: Positive\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This is the link to the article\"\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[Sentiment]: Neutral\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This new music video was incredible\"\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[Sentiment]:\"\"\"\u001B[39;00m,\n",
       "\u001B[1;32m     16\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n",
       "\u001B[1;32m     17\u001B[0m )\n",
       "\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622124>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# With 1 example for each sentiment, the model is more likely to understand!\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each tweet, describe its sentiment:\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[Tweet]: \"I hate it when my phone battery dies.\"\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[Sentiment]: Negative\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[Tweet]: \"My day has been 👍\"\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[Sentiment]: Positive\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This is the link to the article\"\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[Sentiment]: Neutral\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m[Tweet]: \"This new music video was incredible\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[Sentiment]:\"\"\"\u001B[39;00m,\n\u001B[1;32m     16\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With 1 example for each sentiment, the model is more likely to understand!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"I hate it when my phone battery dies.\"\n",
    "[Sentiment]: Negative\n",
    "###\n",
    "[Tweet]: \"My day has been 👍\"\n",
    "[Sentiment]: Positive\n",
    "###\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b9cfa7-3658-42e3-a9c9-d28fb2df0223",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Just for fun, we show a few more examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "006f277a-3f9a-434e-a7d0-bdfad4a07c53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622126>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# The model isn't ready to serve drinks!\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each food, suggest a good drink pairing:\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[food]: tapas\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[drink]: wine\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[food]: pizza\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[drink]: soda\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m[food]: jalapenos poppers\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[drink]: beer\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m[food]: scone\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[drink]:\"\"\"\u001B[39;00m,\n",
       "\u001B[1;32m     16\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n",
       "\u001B[1;32m     17\u001B[0m )\n",
       "\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622126>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# The model isn't ready to serve drinks!\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"For each food, suggest a good drink pairing:\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[food]: tapas\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[drink]: wine\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[food]: pizza\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[drink]: soda\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m[food]: jalapenos poppers\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[drink]: beer\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m[food]: scone\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[drink]:\"\"\"\u001B[39;00m,\n\u001B[1;32m     16\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The model isn't ready to serve drinks!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each food, suggest a good drink pairing:\n",
    "\n",
    "[food]: tapas\n",
    "[drink]: wine\n",
    "###\n",
    "[food]: pizza\n",
    "[drink]: soda\n",
    "###\n",
    "[food]: jalapenos poppers\n",
    "[drink]: beer\n",
    "###\n",
    "[food]: scone\n",
    "[drink]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a31d8a9f-8f65-4265-87c7-36bb36d2834c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622127>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This example sometimes works and sometimes does not, when sampling.  Too abstract?\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[word]: happy\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[description]: smiling, laughing, clapping\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[word]: nervous\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[description]: glancing around quickly, sweating, fidgeting\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m[word]: sleepy\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[description]: heavy-lidded, slumping, rubbing eyes\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m[word]: confused\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[description]:\"\"\"\u001B[39;00m,\n",
       "\u001B[1;32m     16\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n",
       "\u001B[1;32m     17\u001B[0m )\n",
       "\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622127>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This example sometimes works and sometimes does not, when sampling.  Too abstract?\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124;03m\"\"\"Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m[word]: happy\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[description]: smiling, laughing, clapping\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m[word]: nervous\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[description]: glancing around quickly, sweating, fidgeting\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m[word]: sleepy\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[description]: heavy-lidded, slumping, rubbing eyes\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m[word]: confused\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[description]:\"\"\"\u001B[39;00m,\n\u001B[1;32m     16\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This example sometimes works and sometimes does not, when sampling.  Too abstract?\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\n",
    "\n",
    "[word]: happy\n",
    "[description]: smiling, laughing, clapping\n",
    "###\n",
    "[word]: nervous\n",
    "[description]: glancing around quickly, sweating, fidgeting\n",
    "###\n",
    "[word]: sleepy\n",
    "[description]: heavy-lidded, slumping, rubbing eyes\n",
    "###\n",
    "[word]: confused\n",
    "[description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8540db7d-3f8a-4361-abe7-c43fdec529b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622128>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We override max_new_tokens to generate longer answers.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# These book descriptions were taken from their corresponding Wikipedia pages.\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n",
       "\u001B[1;32m      4\u001B[0m     \u001B[38;5;124;03m\"\"\"Generate a book summary from the title:\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m \n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[book title]: \"Stranger in a Strange Land\"\u001B[39;00m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[book title]: \"The Adventures of Tom Sawyer\"\u001B[39;00m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[book title]: \"Dune\"\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[book title]: \"Blue Mars\"\u001B[39;00m\n",
       "\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m[book description]:\"\"\"\u001B[39;00m,\n",
       "\u001B[1;32m     17\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n",
       "\u001B[1;32m     18\u001B[0m     max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n",
       "\u001B[1;32m     19\u001B[0m )\n",
       "\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622128>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We override max_new_tokens to generate longer answers.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# These book descriptions were taken from their corresponding Wikipedia pages.\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m results \u001B[38;5;241m=\u001B[39m few_shot_pipeline(\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124;03m\"\"\"Generate a book summary from the title:\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m[book title]: \"Stranger in a Strange Land\"\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m[book title]: \"The Adventures of Tom Sawyer\"\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m[book title]: \"Dune\"\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m###\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m[book title]: \"Blue Mars\"\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m[book description]:\"\"\"\u001B[39;00m,\n\u001B[1;32m     17\u001B[0m     eos_token_id\u001B[38;5;241m=\u001B[39meos_token_id,\n\u001B[1;32m     18\u001B[0m     max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'few_shot_pipeline' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'few_shot_pipeline' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We override max_new_tokens to generate longer answers.\n",
    "# These book descriptions were taken from their corresponding Wikipedia pages.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"Generate a book summary from the title:\n",
    "\n",
    "[book title]: \"Stranger in a Strange Land\"\n",
    "[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\n",
    "###\n",
    "[book title]: \"The Adventures of Tom Sawyer\"\n",
    "[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\n",
    "###\n",
    "[book title]: \"Dune\"\n",
    "[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\n",
    "###\n",
    "[book title]: \"Blue Mars\"\n",
    "[book description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    "    max_new_tokens=50,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510e42b3-570f-4af8-ae1a-96d488336a77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Prompt engineering** is a new but critical technique for working with LLMs.  You saw some brief examples above.  As you use more general and powerful models, constructing good prompts becomes ever more important.  Some great resources to learn more are:\n",
    "* [Wikipedia](https://en.wikipedia.org/wiki/Prompt_engineering) for a brief overview\n",
    "* [Best practices for prompt engineering with OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
    "* [🧠 Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts) for fun examples with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ad8dd7c-dd4f-4762-aacf-724d182ec886",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Hugging Face APIs\n",
    "\n",
    "In this section, we dive into some more details on Hugging Face APIs.\n",
    "* Search and sampling to generate text\n",
    "* Auto* loaders for tokenizers and models\n",
    "* Model-specific loaders\n",
    "\n",
    "Recall the `xsum` dataset from the **Summarization** section above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c667be72-6415-495b-a8e2-181fd433aa79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622131>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m display(\u001B[43mxsum_sample\u001B[49m\u001B[38;5;241m.\u001B[39mto_pandas())\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'xsum_sample' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622131>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m display(\u001B[43mxsum_sample\u001B[49m\u001B[38;5;241m.\u001B[39mto_pandas())\n\n\u001B[0;31mNameError\u001B[0m: name 'xsum_sample' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'xsum_sample' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b64f948-6f0b-4c6d-9d53-2024699bbc56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Search and sampling in inference\n",
    "\n",
    "You may see parameters like `num_beams`, `do_sample`, etc. specified in Hugging Face pipelines.  These are inference configurations.\n",
    "\n",
    "LLMs work by predicting (generating) the next token, then the next, and so on.  The goal is to generate a high probability sequence of tokens, which is essentially a search through the (enormous) space of potential sequences.\n",
    "\n",
    "To do this search, LLMs use one of two main methods:\n",
    "* **Search**: Given the tokens generated so far, pick the next most likely token in a \"search.\"\n",
    "   * **Greedy search** (default): Pick the single next most likely token in a greedy search.\n",
    "   * **Beam search**: Greedy search can be extended via beam search, which searches down several sequence paths, via the parameter `num_beams`.\n",
    "* **Sampling**: Given the tokens generated so far, pick the next token by sampling from the predicted distribution of tokens.\n",
    "   * **Top-K sampling**: The parameter `top_k` modifies sampling by limiting it to the `k` most likely tokens.\n",
    "   * **Top-p sampling**: The parameter `top_p` modifies sampling by limiting it to the most likely tokens up to probability mass `p`.\n",
    "\n",
    "You can toggle between search and sampling via parameter `do_sample`.\n",
    "\n",
    "For more background on search and sampling, see [this Hugging Face blog post](https://huggingface.co/blog/how-to-generate).\n",
    "\n",
    "We will illustrate these various options below using our summarization pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32dc8cd8-dea0-4034-ad28-8c2e52303fa7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622133>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We previously called the summarization pipeline using the default inference configuration.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# This does greedy search.\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622133>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We previously called the summarization pipeline using the default inference configuration.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# This does greedy search.\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'summarizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We previously called the summarization pipeline using the default inference configuration.\n",
    "# This does greedy search.\n",
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff3f6ef4-2dae-4884-8f09-0a0af4fd178a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622134>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We can instead do a beam search by specifying num_beams.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# This takes longer to run, but it might find a better (more likely) sequence of text.\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m], num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622134>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We can instead do a beam search by specifying num_beams.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# This takes longer to run, but it might find a better (more likely) sequence of text.\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m], num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\n\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'summarizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can instead do a beam search by specifying num_beams.\n",
    "# This takes longer to run, but it might find a better (more likely) sequence of text.\n",
    "summarizer(xsum_sample[\"document\"][0], num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bf37495-4cfd-455a-b886-35c56a016154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622135>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Alternatively, we could use sampling.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m], do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622135>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Alternatively, we could use sampling.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m], do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\n\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'summarizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternatively, we could use sampling.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e451f18-f800-4e2a-b93b-fbf57c156846",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622136>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m], do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, top_k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, top_p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622136>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43msummarizer\u001B[49m(xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m], do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, top_k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, top_p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n\n\u001B[0;31mNameError\u001B[0m: name 'summarizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'summarizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True, top_k=10, top_p=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "683cb9ae-c639-4d44-89cd-9f50b4bf42ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Auto* loaders for tokenizers and models\n",
    "\n",
    "We have already seen the `dataset` and `pipeline` abstractions from Hugging Face.  While a `pipeline` is a quick way to set up an LLM for a given task, the slightly lower-level abstractions `model` and `tokenizer` permit a bit more control over options.  We will show how to use those briefly, following this pattern:\n",
    "\n",
    "* Given input articles.\n",
    "* Tokenize them (converting to token indices).\n",
    "* Apply the model on the tokenized data to generate summaries (represented as token indices).\n",
    "* Decode the summaries into human-readable text.\n",
    "\n",
    "We will first look at the [Auto* classes](https://huggingface.co/docs/transformers/model_doc/auto) for tokenizers and model types which can simplify loading pre-trained tokenizers and models.\n",
    "\n",
    "API docs:\n",
    "* [AutoTokenizer](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer)\n",
    "* [AutoModelForSeq2SeqLM](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af433ce1-ff40-4e17-8f17-ac15cb153edc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622138>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Load the pre-trained tokenizer and model.\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets)\n",
       "\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSeq2SeqLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622138>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Load the pre-trained tokenizer and model.\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets)\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSeq2SeqLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets)\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the pre-trained tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b932741-05d5-4477-bd03-2bb2aefd72ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622139>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# For summarization, T5-small expects a prefix \"summarize: \", so we prepend that to each article as a prompt.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m articles \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m article: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummarize: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m article, xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n",
       "\u001B[1;32m      3\u001B[0m display(pd\u001B[38;5;241m.\u001B[39mDataFrame(articles, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'xsum_sample' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622139>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# For summarization, T5-small expects a prefix \"summarize: \", so we prepend that to each article as a prompt.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m articles \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m article: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummarize: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m article, xsum_sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n\u001B[1;32m      3\u001B[0m display(pd\u001B[38;5;241m.\u001B[39mDataFrame(articles, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n\n\u001B[0;31mNameError\u001B[0m: name 'xsum_sample' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'xsum_sample' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For summarization, T5-small expects a prefix \"summarize: \", so we prepend that to each article as a prompt.\n",
    "articles = list(map(lambda article: \"summarize: \" + article, xsum_sample[\"document\"]))\n",
    "display(pd.DataFrame(articles, columns=[\"prompts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7674a7b-64d1-4cd3-b1f4-78eff94239e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622140>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Tokenize the input\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(\n",
       "\u001B[1;32m      3\u001B[0m     articles, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m )\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622140>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Tokenize the input\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(\n\u001B[1;32m      3\u001B[0m     articles, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\n\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'tokenizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "print(\"input_ids:\")\n",
    "print(inputs[\"input_ids\"])\n",
    "print(\"attention_mask:\")\n",
    "print(inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af1b3f89-5e93-4d88-9bc7-2bdd7b3099c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622141>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Generate summaries\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m summary_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n",
       "\u001B[1;32m      3\u001B[0m     inputs\u001B[38;5;241m.\u001B[39minput_ids,\n",
       "\u001B[1;32m      4\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39minputs\u001B[38;5;241m.\u001B[39mattention_mask,\n",
       "\u001B[1;32m      5\u001B[0m     num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n",
       "\u001B[1;32m      6\u001B[0m     min_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n",
       "\u001B[1;32m      7\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n",
       "\u001B[1;32m      8\u001B[0m )\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(summary_ids)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622141>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Generate summaries\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m summary_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m      3\u001B[0m     inputs\u001B[38;5;241m.\u001B[39minput_ids,\n\u001B[1;32m      4\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39minputs\u001B[38;5;241m.\u001B[39mattention_mask,\n\u001B[1;32m      5\u001B[0m     num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      6\u001B[0m     min_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m      7\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(summary_ids)\n\n\u001B[0;31mNameError\u001B[0m: name 'model' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'model' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate summaries\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "print(summary_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d432fb9b-d48a-40b5-9cba-4d6acfce9539",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622142>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Decode the generated summaries\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m decoded_summaries \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(summary_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\u001B[1;32m      3\u001B[0m display(pd\u001B[38;5;241m.\u001B[39mDataFrame(decoded_summaries, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoded_summaries\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622142>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Decode the generated summaries\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m decoded_summaries \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(summary_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m display(pd\u001B[38;5;241m.\u001B[39mDataFrame(decoded_summaries, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoded_summaries\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n\n\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'tokenizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decode the generated summaries\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da419d03-3c8d-45a0-8a10-dd3afa703278",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Model-specific tokenizer and model loaders\n",
    "\n",
    "You can also more directly load specific tokenizer and model types, rather than relying on `Auto*` classes to choose the right ones for you.\n",
    "\n",
    "API docs:\n",
    "* [T5Tokenizer](https://huggingface.co/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer)\n",
    "* [T5ForConditionalGeneration](https://huggingface.co/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700e393e-1a86-4313-ad63-d7f5c9ef15ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622144>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m T5Tokenizer, T5ForConditionalGeneration\n",
       "\u001B[0;32m----> 3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m T5Tokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets)\n",
       "\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m T5ForConditionalGeneration\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n",
       "\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets\n",
       "\u001B[1;32m      6\u001B[0m )\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622144>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m T5Tokenizer, T5ForConditionalGeneration\n\u001B[0;32m----> 3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m T5Tokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets)\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m T5ForConditionalGeneration\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt5-small\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache_dir\u001B[38;5;241m=\u001B[39mDA\u001B[38;5;241m.\u001B[39mpaths\u001B[38;5;241m.\u001B[39mdatasets\n\u001B[1;32m      6\u001B[0m )\n\n\u001B[0;31mNameError\u001B[0m: name 'DA' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'DA' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"t5-small\", cache_dir=DA.paths.datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9807b117-0cc5-4a15-90c1-066c066cde6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-410409246622145>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# The tokenizer and model can then be used similarly to how we used the ones loaded by the Auto* classes.\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(\n",
       "\u001B[1;32m      3\u001B[0m     articles, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m )\n",
       "\u001B[1;32m      5\u001B[0m summary_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n",
       "\u001B[1;32m      6\u001B[0m     inputs\u001B[38;5;241m.\u001B[39minput_ids,\n",
       "\u001B[1;32m      7\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39minputs\u001B[38;5;241m.\u001B[39mattention_mask,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n",
       "\u001B[1;32m     11\u001B[0m )\n",
       "\u001B[1;32m     12\u001B[0m decoded_summaries \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(summary_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-410409246622145>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# The tokenizer and model can then be used similarly to how we used the ones loaded by the Auto* classes.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(\n\u001B[1;32m      3\u001B[0m     articles, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m summary_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m      6\u001B[0m     inputs\u001B[38;5;241m.\u001B[39minput_ids,\n\u001B[1;32m      7\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39minputs\u001B[38;5;241m.\u001B[39mattention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     12\u001B[0m decoded_summaries \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(summary_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\n\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'tokenizer' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The tokenizer and model can then be used similarly to how we used the ones loaded by the Auto* classes.\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4518183-063a-483b-9339-35d04e3664c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "We've covered some common LLM applications and seen how to get started with them quickly using pre-trained models from the Hugging Face Hub.  We've also see how to tweak some configurations.\n",
    "\n",
    "But how did we find those models for our tasks?  In the lab, you will find new pre-trained models for tasks, using the Hugging Face Hub.  You will also explore tweaking model configurations to gain intuition about their effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81e963e-ebd3-47b5-9b6a-94d932136b41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "LLM 01 - LLMs with Hugging Face",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
